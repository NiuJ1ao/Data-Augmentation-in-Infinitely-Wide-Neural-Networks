WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
[2022-08-12 10:17:18,240 INFO] (util:27) Namespace(augment_X=None, augment_y=None, batch_size=0, device_count=-1, epochs=1, lr=0.1, model='fcn', momentum=0.9, num_inducing_points=750, select_method='random')
[2022-08-12 10:17:19,039 INFO] (data_loader:91) MNIST: (10000, 784) train, (10000, 784) test samples.
[2022-08-12 10:17:19,086 INFO] (snngp_vary_inducing_random:31) 
----Number of inducing point: 500----
[2022-08-12 10:17:19,227 INFO] (snngp_inference:59) inducing_points shape: (500, 784)
[2022-08-12 10:17:19,239 INFO] (snngp:272) Optimizing...
2022-08-12 10:17:24.762223: E external/org_tensorflow/tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] Constant folding an instruction is taking > 1s:

  dot.2 (displaying the full instruction incurs a runtime overhead. Raise your logging level to 4 or above).

This isn't necessarily a bug; constant-folding is inherently a trade-off between compilation time and speed at runtime.  XLA has some guards that attempt to keep constant folding from taking too long, but fundamentally you'll always be able to come up with an input program that takes a long time.

If you'd like to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
2022-08-12 10:17:25.531714: E external/org_tensorflow/tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 1.769571555s
Constant folding an instruction is taking > 1s:

  dot.2 (displaying the full instruction incurs a runtime overhead. Raise your logging level to 4 or above).

This isn't necessarily a bug; constant-folding is inherently a trade-off between compilation time and speed at runtime.  XLA has some guards that attempt to keep constant folding from taking too long, but fundamentally you'll always be able to come up with an input program that takes a long time.

If you'd like to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
2022-08-12 10:17:27.803190: E external/org_tensorflow/tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] Constant folding an instruction is taking > 2s:

  dot.5 (displaying the full instruction incurs a runtime overhead. Raise your logging level to 4 or above).

This isn't necessarily a bug; constant-folding is inherently a trade-off between compilation time and speed at runtime.  XLA has some guards that attempt to keep constant folding from taking too long, but fundamentally you'll always be able to come up with an input program that takes a long time.

If you'd like to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
2022-08-12 10:18:01.281978: E external/org_tensorflow/tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 35.478852313s
Constant folding an instruction is taking > 2s:

  dot.5 (displaying the full instruction incurs a runtime overhead. Raise your logging level to 4 or above).

This isn't necessarily a bug; constant-folding is inherently a trade-off between compilation time and speed at runtime.  XLA has some guards that attempt to keep constant folding from taking too long, but fundamentally you'll always be able to come up with an input program that takes a long time.

If you'd like to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
[2022-08-12 10:18:23,137 INFO] (snngp:280) Optimized for 14 iters; Success: True; Result: [1.06166981 0.08572686], 0.025437949623704527
[2022-08-12 10:18:35,668 INFO] (snngp_vary_inducing_random:46) LML: 4728.64283134373
[2022-08-12 10:18:39,326 INFO] (snngp_vary_inducing_random:48) ELBO: 3212.104727192672
[2022-08-12 10:18:39,528 INFO] (snngp_vary_inducing_random:50) EUBO: 8892.912709827724
[2022-08-12 10:18:40,344 INFO] (snngp_vary_inducing_random:54) Loss: 0.15187006024497898
[2022-08-12 10:18:40,423 INFO] (snngp_vary_inducing_random:56) Accuracy: 92.73%
[2022-08-12 10:18:40,434 INFO] (snngp_vary_inducing_random:31) 
----Number of inducing point: 1000----
[2022-08-12 10:18:40,539 INFO] (snngp_inference:59) inducing_points shape: (1000, 784)
[2022-08-12 10:18:40,540 INFO] (snngp:272) Optimizing...
2022-08-12 10:18:48.971898: E external/org_tensorflow/tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] Constant folding an instruction is taking > 4s:

  dot.2 (displaying the full instruction incurs a runtime overhead. Raise your logging level to 4 or above).

This isn't necessarily a bug; constant-folding is inherently a trade-off between compilation time and speed at runtime.  XLA has some guards that attempt to keep constant folding from taking too long, but fundamentally you'll always be able to come up with an input program that takes a long time.

If you'd like to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
2022-08-12 10:18:52.083971: E external/org_tensorflow/tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 7.112136333s
Constant folding an instruction is taking > 4s:

  dot.2 (displaying the full instruction incurs a runtime overhead. Raise your logging level to 4 or above).

This isn't necessarily a bug; constant-folding is inherently a trade-off between compilation time and speed at runtime.  XLA has some guards that attempt to keep constant folding from taking too long, but fundamentally you'll always be able to come up with an input program that takes a long time.

If you'd like to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
2022-08-12 10:19:00.369469: E external/org_tensorflow/tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] Constant folding an instruction is taking > 8s:

  dot.5 (displaying the full instruction incurs a runtime overhead. Raise your logging level to 4 or above).

This isn't necessarily a bug; constant-folding is inherently a trade-off between compilation time and speed at runtime.  XLA has some guards that attempt to keep constant folding from taking too long, but fundamentally you'll always be able to come up with an input program that takes a long time.

If you'd like to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
2022-08-12 10:20:03.826633: E external/org_tensorflow/tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 1m11.457229663s
Constant folding an instruction is taking > 8s:

  dot.5 (displaying the full instruction incurs a runtime overhead. Raise your logging level to 4 or above).

This isn't necessarily a bug; constant-folding is inherently a trade-off between compilation time and speed at runtime.  XLA has some guards that attempt to keep constant folding from taking too long, but fundamentally you'll always be able to come up with an input program that takes a long time.

If you'd like to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
[2022-08-12 10:20:56,658 INFO] (snngp:280) Optimized for 15 iters; Success: True; Result: [1.10595896 0.13472447], 0.020640424025387617
[2022-08-12 10:21:08,526 INFO] (snngp_vary_inducing_random:46) LML: 5281.993442188129
[2022-08-12 10:21:12,522 INFO] (snngp_vary_inducing_random:48) ELBO: 4002.9438333301086
[2022-08-12 10:21:13,013 INFO] (snngp_vary_inducing_random:50) EUBO: 9760.585828632704
[2022-08-12 10:21:14,364 INFO] (snngp_vary_inducing_random:54) Loss: 0.1376556441982208
[2022-08-12 10:21:14,366 INFO] (snngp_vary_inducing_random:56) Accuracy: 94.13%
[2022-08-12 10:21:14,366 INFO] (snngp_vary_inducing_random:31) 
----Number of inducing point: 1500----
[2022-08-12 10:21:14,477 INFO] (snngp_inference:59) inducing_points shape: (1500, 784)
[2022-08-12 10:21:14,478 INFO] (snngp:272) Optimizing...
2022-08-12 10:21:35.022533: E external/org_tensorflow/tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] Constant folding an instruction is taking > 16s:

  dot.2 (displaying the full instruction incurs a runtime overhead. Raise your logging level to 4 or above).

This isn't necessarily a bug; constant-folding is inherently a trade-off between compilation time and speed at runtime.  XLA has some guards that attempt to keep constant folding from taking too long, but fundamentally you'll always be able to come up with an input program that takes a long time.

If you'd like to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
2022-08-12 10:21:35.206883: E external/org_tensorflow/tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 16.184416072s
Constant folding an instruction is taking > 16s:

  dot.2 (displaying the full instruction incurs a runtime overhead. Raise your logging level to 4 or above).

This isn't necessarily a bug; constant-folding is inherently a trade-off between compilation time and speed at runtime.  XLA has some guards that attempt to keep constant folding from taking too long, but fundamentally you'll always be able to come up with an input program that takes a long time.

If you'd like to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
2022-08-12 10:22:07.517262: E external/org_tensorflow/tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] Constant folding an instruction is taking > 32s:

  dot.5 (displaying the full instruction incurs a runtime overhead. Raise your logging level to 4 or above).

This isn't necessarily a bug; constant-folding is inherently a trade-off between compilation time and speed at runtime.  XLA has some guards that attempt to keep constant folding from taking too long, but fundamentally you'll always be able to come up with an input program that takes a long time.

If you'd like to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
2022-08-12 10:23:22.724428: E external/org_tensorflow/tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 1m47.207231529s
Constant folding an instruction is taking > 32s:

  dot.5 (displaying the full instruction incurs a runtime overhead. Raise your logging level to 4 or above).

This isn't necessarily a bug; constant-folding is inherently a trade-off between compilation time and speed at runtime.  XLA has some guards that attempt to keep constant folding from taking too long, but fundamentally you'll always be able to come up with an input program that takes a long time.

If you'd like to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
[2022-08-12 10:24:38,721 INFO] (snngp:280) Optimized for 11 iters; Success: True; Result: [1.13271601 0.15630892], 0.018470737905295916
[2022-08-12 10:24:49,906 INFO] (snngp_vary_inducing_random:46) LML: 5562.816629603563
[2022-08-12 10:24:55,029 INFO] (snngp_vary_inducing_random:48) ELBO: 4390.846137651025
[2022-08-12 10:24:55,938 INFO] (snngp_vary_inducing_random:50) EUBO: 10170.605987349221
[2022-08-12 10:24:57,811 INFO] (snngp_vary_inducing_random:54) Loss: 0.13162849591036888
[2022-08-12 10:24:57,811 INFO] (snngp_vary_inducing_random:56) Accuracy: 94.85%
[2022-08-12 10:24:57,812 INFO] (snngp_vary_inducing_random:31) 
----Number of inducing point: 2000----
[2022-08-12 10:24:57,913 INFO] (snngp_inference:59) inducing_points shape: (2000, 784)
[2022-08-12 10:24:57,913 INFO] (snngp:272) Optimizing...
2022-08-12 10:26:35.619651: E external/org_tensorflow/tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] Constant folding an instruction is taking > 1m4s:

  dot.5 (displaying the full instruction incurs a runtime overhead. Raise your logging level to 4 or above).

This isn't necessarily a bug; constant-folding is inherently a trade-off between compilation time and speed at runtime.  XLA has some guards that attempt to keep constant folding from taking too long, but fundamentally you'll always be able to come up with an input program that takes a long time.

If you'd like to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
2022-08-12 10:27:54.601005: E external/org_tensorflow/tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 2m22.981422092s
Constant folding an instruction is taking > 1m4s:

  dot.5 (displaying the full instruction incurs a runtime overhead. Raise your logging level to 4 or above).

This isn't necessarily a bug; constant-folding is inherently a trade-off between compilation time and speed at runtime.  XLA has some guards that attempt to keep constant folding from taking too long, but fundamentally you'll always be able to come up with an input program that takes a long time.

If you'd like to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
[2022-08-12 10:30:02,287 INFO] (snngp:280) Optimized for 12 iters; Success: True; Result: [1.15069194 0.16287634], 0.016993476455129563
[2022-08-12 10:30:13,879 INFO] (snngp_vary_inducing_random:46) LML: 5759.740083703075
[2022-08-12 10:30:20,321 INFO] (snngp_vary_inducing_random:48) ELBO: 4671.599029054632
[2022-08-12 10:30:21,743 INFO] (snngp_vary_inducing_random:50) EUBO: 10460.019788700296
[2022-08-12 10:30:24,334 INFO] (snngp_vary_inducing_random:54) Loss: 0.1279810530217579
[2022-08-12 10:30:24,335 INFO] (snngp_vary_inducing_random:56) Accuracy: 95.06%
[2022-08-12 10:30:24,335 INFO] (snngp_vary_inducing_random:31) 
----Number of inducing point: 2500----
[2022-08-12 10:30:24,441 INFO] (snngp_inference:59) inducing_points shape: (2500, 784)
[2022-08-12 10:30:24,441 INFO] (snngp:272) Optimizing...
2022-08-12 10:33:22.094314: E external/org_tensorflow/tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] Constant folding an instruction is taking > 2m8s:

  dot.5 (displaying the full instruction incurs a runtime overhead. Raise your logging level to 4 or above).

This isn't necessarily a bug; constant-folding is inherently a trade-off between compilation time and speed at runtime.  XLA has some guards that attempt to keep constant folding from taking too long, but fundamentally you'll always be able to come up with an input program that takes a long time.

If you'd like to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
2022-08-12 10:34:14.676680: E external/org_tensorflow/tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 3m0.582432877s
Constant folding an instruction is taking > 2m8s:

  dot.5 (displaying the full instruction incurs a runtime overhead. Raise your logging level to 4 or above).

This isn't necessarily a bug; constant-folding is inherently a trade-off between compilation time and speed at runtime.  XLA has some guards that attempt to keep constant folding from taking too long, but fundamentally you'll always be able to come up with an input program that takes a long time.

If you'd like to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
[2022-08-12 10:35:47,885 INFO] (snngp:280) Optimized for 4 iters; Success: True; Result: [1.1671402  0.16275077], 0.015818441365671808
[2022-08-12 10:36:00,135 INFO] (snngp_vary_inducing_random:46) LML: 5929.0499955302075
[2022-08-12 10:36:07,607 INFO] (snngp_vary_inducing_random:48) ELBO: 4893.849068771044
[2022-08-12 10:36:09,979 INFO] (snngp_vary_inducing_random:50) EUBO: 10684.210145263334
[2022-08-12 10:36:13,352 INFO] (snngp_vary_inducing_random:54) Loss: 0.12471238640174007
[2022-08-12 10:36:13,353 INFO] (snngp_vary_inducing_random:56) Accuracy: 95.36%
[2022-08-12 10:36:13,353 INFO] (snngp_vary_inducing_random:31) 
----Number of inducing point: 3000----
[2022-08-12 10:36:13,462 INFO] (snngp_inference:59) inducing_points shape: (3000, 784)
[2022-08-12 10:36:13,462 INFO] (snngp:272) Optimizing...
[2022-08-12 10:45:00,841 INFO] (snngp:280) Optimized for 10 iters; Success: True; Result: [1.17899928 0.16521842], 0.015012097554927075
[2022-08-12 10:45:12,523 INFO] (snngp_vary_inducing_random:46) LML: 6045.962482696887
[2022-08-12 10:45:22,051 INFO] (snngp_vary_inducing_random:48) ELBO: 5055.458768428738
[2022-08-12 10:45:25,093 INFO] (snngp_vary_inducing_random:50) EUBO: 10829.035653281553
[2022-08-12 10:45:29,538 INFO] (snngp_vary_inducing_random:54) Loss: 0.12267753885330837
[2022-08-12 10:45:29,538 INFO] (snngp_vary_inducing_random:56) Accuracy: 95.53%
[2022-08-12 10:45:29,539 INFO] (snngp_vary_inducing_random:31) 
----Number of inducing point: 3500----
[2022-08-12 10:45:29,685 INFO] (snngp_inference:59) inducing_points shape: (3500, 784)
[2022-08-12 10:45:29,685 INFO] (snngp:272) Optimizing...
[2022-08-12 10:55:49,233 INFO] (snngp:280) Optimized for 8 iters; Success: True; Result: [1.19171167 0.16595262], 0.014146913677375313
[2022-08-12 10:56:00,665 INFO] (snngp_vary_inducing_random:46) LML: 6172.859234714188
[2022-08-12 10:56:11,340 INFO] (snngp_vary_inducing_random:48) ELBO: 5227.400152091334
[2022-08-12 10:56:15,287 INFO] (snngp_vary_inducing_random:50) EUBO: 10990.881306715959
[2022-08-12 10:56:20,458 INFO] (snngp_vary_inducing_random:54) Loss: 0.12065038868142039
[2022-08-12 10:56:20,459 INFO] (snngp_vary_inducing_random:56) Accuracy: 95.83%
[2022-08-12 10:56:20,459 INFO] (snngp_vary_inducing_random:31) 
----Number of inducing point: 4000----
[2022-08-12 10:56:20,562 INFO] (snngp_inference:59) inducing_points shape: (4000, 784)
[2022-08-12 10:56:20,562 INFO] (snngp:272) Optimizing...
2022-08-12 11:02:35.909541: E external/org_tensorflow/tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] Constant folding an instruction is taking > 4m16s:

  dot.5 (displaying the full instruction incurs a runtime overhead. Raise your logging level to 4 or above).

This isn't necessarily a bug; constant-folding is inherently a trade-off between compilation time and speed at runtime.  XLA has some guards that attempt to keep constant folding from taking too long, but fundamentally you'll always be able to come up with an input program that takes a long time.

If you'd like to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
2022-08-12 11:03:16.688406: E external/org_tensorflow/tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 4m56.782076224s
Constant folding an instruction is taking > 4m16s:

  dot.5 (displaying the full instruction incurs a runtime overhead. Raise your logging level to 4 or above).

This isn't necessarily a bug; constant-folding is inherently a trade-off between compilation time and speed at runtime.  XLA has some guards that attempt to keep constant folding from taking too long, but fundamentally you'll always be able to come up with an input program that takes a long time.

If you'd like to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
[2022-08-12 11:09:45,681 INFO] (snngp:280) Optimized for 9 iters; Success: True; Result: [1.20285032 0.16459783], 0.013352744263752762
[2022-08-12 11:09:57,712 INFO] (snngp_vary_inducing_random:46) LML: 6289.094607438361
[2022-08-12 11:10:10,438 INFO] (snngp_vary_inducing_random:48) ELBO: 5385.847645413133
[2022-08-12 11:10:15,623 INFO] (snngp_vary_inducing_random:50) EUBO: 11148.096025215606
[2022-08-12 11:10:21,972 INFO] (snngp_vary_inducing_random:54) Loss: 0.11896678997155133
[2022-08-12 11:10:21,973 INFO] (snngp_vary_inducing_random:56) Accuracy: 95.85%
[2022-08-12 11:10:21,973 INFO] (snngp_vary_inducing_random:31) 
----Number of inducing point: 4500----
[2022-08-12 11:10:22,080 INFO] (snngp_inference:59) inducing_points shape: (4500, 784)
[2022-08-12 11:10:22,080 INFO] (snngp:272) Optimizing...
[2022-08-12 11:26:25,694 INFO] (snngp:280) Optimized for 9 iters; Success: True; Result: [1.21423222 0.16371945], 0.012687600670253436
[2022-08-12 11:26:37,223 INFO] (snngp_vary_inducing_random:46) LML: 6393.086694192507
[2022-08-12 11:26:51,941 INFO] (snngp_vary_inducing_random:48) ELBO: 5519.507892353143
[2022-08-12 11:26:58,118 INFO] (snngp_vary_inducing_random:50) EUBO: 11255.067497229706
[2022-08-12 11:27:05,154 INFO] (snngp_vary_inducing_random:54) Loss: 0.11735513872064997
[2022-08-12 11:27:05,154 INFO] (snngp_vary_inducing_random:56) Accuracy: 96.03%
[2022-08-12 11:27:05,155 INFO] (snngp_vary_inducing_random:31) 
----Number of inducing point: 5000----
[2022-08-12 11:27:05,275 INFO] (snngp_inference:59) inducing_points shape: (5000, 784)
[2022-08-12 11:27:05,275 INFO] (snngp:272) Optimizing...
[2022-08-12 11:41:10,312 INFO] (snngp:280) Optimized for 11 iters; Success: True; Result: [1.22688729 0.16028362], 0.01183383500164979
[2022-08-12 11:41:21,976 INFO] (snngp_vary_inducing_random:46) LML: 6521.663409898846
[2022-08-12 11:41:39,536 INFO] (snngp_vary_inducing_random:48) ELBO: 5690.795359911694
[2022-08-12 11:41:46,911 INFO] (snngp_vary_inducing_random:50) EUBO: 11423.748984818758
[2022-08-12 11:41:55,785 INFO] (snngp_vary_inducing_random:54) Loss: 0.11585761884884921
[2022-08-12 11:41:55,785 INFO] (snngp_vary_inducing_random:56) Accuracy: 96.14%
[2022-08-12 11:41:55,786 INFO] (snngp_vary_inducing_random:31) 
----Number of inducing point: 5500----
[2022-08-12 11:41:55,897 INFO] (snngp_inference:59) inducing_points shape: (5500, 784)
[2022-08-12 11:41:55,898 INFO] (snngp:272) Optimizing...
[2022-08-12 11:52:23,592 INFO] (snngp:280) Optimized for 4 iters; Success: True; Result: [1.2355866  0.16022603], 0.011383388509807612
[2022-08-12 11:52:35,612 INFO] (snngp_vary_inducing_random:46) LML: 6594.6096475166505
[2022-08-12 11:52:55,372 INFO] (snngp_vary_inducing_random:48) ELBO: 5779.8600014237645
[2022-08-12 11:53:04,474 INFO] (snngp_vary_inducing_random:50) EUBO: 11480.670911401738
[2022-08-12 11:53:14,013 INFO] (snngp_vary_inducing_random:54) Loss: 0.11483869371276552
[2022-08-12 11:53:14,013 INFO] (snngp_vary_inducing_random:56) Accuracy: 96.09%
[2022-08-12 11:53:14,014 INFO] (snngp_vary_inducing_random:31) 
----Number of inducing point: 6000----
[2022-08-12 11:53:14,129 INFO] (snngp_inference:59) inducing_points shape: (6000, 784)
[2022-08-12 11:53:14,130 INFO] (snngp:272) Optimizing...
[2022-08-12 12:11:42,611 INFO] (snngp:280) Optimized for 8 iters; Success: True; Result: [1.24891382 0.15931935], 0.010580481746022583
[2022-08-12 12:11:54,131 INFO] (snngp_vary_inducing_random:46) LML: 6718.413727521911
[2022-08-12 12:12:16,845 INFO] (snngp_vary_inducing_random:48) ELBO: 5942.778488389626
[2022-08-12 12:12:27,894 INFO] (snngp_vary_inducing_random:50) EUBO: 11629.606064746917
[2022-08-12 12:12:39,112 INFO] (snngp_vary_inducing_random:54) Loss: 0.11351065498410494
[2022-08-12 12:12:39,113 INFO] (snngp_vary_inducing_random:56) Accuracy: 96.34%
[2022-08-12 12:12:39,113 INFO] (snngp_vary_inducing_random:31) 
----Number of inducing point: 6500----
[2022-08-12 12:12:39,256 INFO] (snngp_inference:59) inducing_points shape: (6500, 784)
[2022-08-12 12:12:39,257 INFO] (snngp:272) Optimizing...
[2022-08-12 12:36:59,518 INFO] (snngp:280) Optimized for 10 iters; Success: True; Result: [1.2599192  0.15694714], 0.00992617735199965
[2022-08-12 12:37:11,081 INFO] (snngp_vary_inducing_random:46) LML: 6820.505206267962
[2022-08-12 12:37:37,211 INFO] (snngp_vary_inducing_random:48) ELBO: 6077.95334088471
[2022-08-12 12:37:50,242 INFO] (snngp_vary_inducing_random:50) EUBO: 11739.708908153043
[2022-08-12 12:38:02,973 INFO] (snngp_vary_inducing_random:54) Loss: 0.11225638392365053
[2022-08-12 12:38:02,974 INFO] (snngp_vary_inducing_random:56) Accuracy: 96.46%
[2022-08-12 12:38:02,974 INFO] (snngp_vary_inducing_random:31) 
----Number of inducing point: 7000----
[2022-08-12 12:38:03,126 INFO] (snngp_inference:59) inducing_points shape: (7000, 784)
[2022-08-12 12:38:03,127 INFO] (snngp:272) Optimizing...
[2022-08-12 12:59:03,691 INFO] (snngp:280) Optimized for 9 iters; Success: True; Result: [1.27041958 0.15519159], 0.009429939239464233
[2022-08-12 12:59:15,385 INFO] (snngp_vary_inducing_random:46) LML: 6903.42365866325
[2022-08-12 12:59:45,314 INFO] (snngp_vary_inducing_random:48) ELBO: 6180.048110201258
[2022-08-12 13:00:00,528 INFO] (snngp_vary_inducing_random:50) EUBO: 11783.586237388039
[2022-08-12 13:00:14,693 INFO] (snngp_vary_inducing_random:54) Loss: 0.11141928749313024
[2022-08-12 13:00:14,693 INFO] (snngp_vary_inducing_random:56) Accuracy: 96.45%
[2022-08-12 13:00:14,694 INFO] (snngp_vary_inducing_random:31) 
----Number of inducing point: 7500----
[2022-08-12 13:00:14,817 INFO] (snngp_inference:59) inducing_points shape: (7500, 784)
[2022-08-12 13:00:14,818 INFO] (snngp:272) Optimizing...
[2022-08-12 13:32:42,571 INFO] (snngp:280) Optimized for 11 iters; Success: True; Result: [1.28599512 0.15197054], 0.008516722617881708
[2022-08-12 13:33:00,218 INFO] (snngp_vary_inducing_random:46) LML: 7045.966378311178
[2022-08-12 13:33:52,911 INFO] (snngp_vary_inducing_random:48) ELBO: 6372.77789117531
[2022-08-12 13:34:21,828 INFO] (snngp_vary_inducing_random:50) EUBO: 11947.445726515656
[2022-08-12 13:34:46,524 INFO] (snngp_vary_inducing_random:54) Loss: 0.10990250112582318
[2022-08-12 13:34:46,525 INFO] (snngp_vary_inducing_random:56) Accuracy: 96.59%
[2022-08-12 13:34:46,525 INFO] (snngp_vary_inducing_random:31) 
----Number of inducing point: 8000----
[2022-08-12 13:34:46,691 INFO] (snngp_inference:59) inducing_points shape: (8000, 784)
[2022-08-12 13:34:46,692 INFO] (snngp:272) Optimizing...
[2022-08-12 13:58:33,706 INFO] (snngp:280) Optimized for 5 iters; Success: True; Result: [1.30006349 0.15187096], 0.0078080474115187854
[2022-08-12 13:58:52,966 INFO] (snngp_vary_inducing_random:46) LML: 7160.157685270446
[2022-08-12 13:59:48,850 INFO] (snngp_vary_inducing_random:48) ELBO: 6516.840099576827
[2022-08-12 14:00:20,951 INFO] (snngp_vary_inducing_random:50) EUBO: 12047.406909423114
[2022-08-12 14:00:48,094 INFO] (snngp_vary_inducing_random:54) Loss: 0.10866478879827465
[2022-08-12 14:00:48,095 INFO] (snngp_vary_inducing_random:56) Accuracy: 96.76%
[2022-08-12 14:07:26,958 INFO] (snngp_vary_inducing_random:31) 
----Number of inducing point: 8500----
[2022-08-12 14:07:27,177 INFO] (snngp_inference:51) inducing_points shape: (8500, 784)
[2022-08-12 14:07:27,195 INFO] (snngp:272) Optimizing...
[2022-08-12 15:00:44,871 INFO] (snngp:280) Optimized for 13 iters; Success: True; Result: [1.32008032 0.14719602], 0.006728565357866027
[2022-08-12 15:01:03,465 INFO] (snngp_vary_inducing_random:46) LML: 7332.469180490964
[2022-08-12 15:02:08,583 INFO] (snngp_vary_inducing_random:48) ELBO: 6748.952400668357
[2022-08-12 15:02:43,845 INFO] (snngp_vary_inducing_random:50) EUBO: 12228.338427452018
[2022-08-12 15:03:09,086 INFO] (snngp_vary_inducing_random:54) Loss: 0.10726859913556692
[2022-08-12 15:03:09,224 INFO] (snngp_vary_inducing_random:56) Accuracy: 96.86%
[2022-08-12 15:03:09,242 INFO] (snngp_vary_inducing_random:31) 
----Number of inducing point: 9000----
[2022-08-12 15:03:09,418 INFO] (snngp_inference:51) inducing_points shape: (9000, 784)
[2022-08-12 15:03:09,418 INFO] (snngp:272) Optimizing...
[2022-08-12 16:02:16,572 INFO] (snngp:280) Optimized for 11 iters; Success: True; Result: [1.33714536 0.14623605], 0.0059581199409044685
[2022-08-12 16:02:27,971 INFO] (snngp_vary_inducing_random:46) LML: 7459.956099445825
[2022-08-12 16:03:14,958 INFO] (snngp_vary_inducing_random:48) ELBO: 6913.57573025931
[2022-08-12 16:03:40,169 INFO] (snngp_vary_inducing_random:50) EUBO: 12295.990260664295
[2022-08-12 16:04:00,498 INFO] (snngp_vary_inducing_random:54) Loss: 0.10619684591824598
[2022-08-12 16:04:00,499 INFO] (snngp_vary_inducing_random:56) Accuracy: 96.88%
[2022-08-12 16:04:00,499 INFO] (snngp_vary_inducing_random:31) 
----Number of inducing point: 9500----
[2022-08-12 16:04:00,626 INFO] (snngp_inference:51) inducing_points shape: (9500, 784)
[2022-08-12 16:04:00,626 INFO] (snngp:272) Optimizing...
[2022-08-12 16:48:11,313 INFO] (snngp:280) Optimized for 12 iters; Success: True; Result: [1.37191858 0.13892855], 0.004206929587512822
[2022-08-12 16:48:23,068 INFO] (snngp_vary_inducing_random:46) LML: 7745.3688409966435
[2022-08-12 16:49:14,120 INFO] (snngp_vary_inducing_random:48) ELBO: 7308.090564791159
[2022-08-12 16:49:41,679 INFO] (snngp_vary_inducing_random:50) EUBO: 12583.178836441954
[2022-08-12 16:50:03,389 INFO] (snngp_vary_inducing_random:54) Loss: 0.10414963536560917
[2022-08-12 16:50:03,389 INFO] (snngp_vary_inducing_random:56) Accuracy: 97.13%
[2022-08-12 16:50:03,390 INFO] (snngp_vary_inducing_random:31) 
----Number of inducing point: 10000----
[2022-08-12 16:50:03,498 INFO] (snngp_inference:51) inducing_points shape: (10000, 784)
[2022-08-12 16:50:03,498 INFO] (snngp:272) Optimizing...
[2022-08-12 17:51:47,063 INFO] (snngp:280) Optimized for 13 iters; Success: True; Result: [1.46705722 0.13346611], 0.00012734876759368396
[2022-08-12 17:51:58,274 INFO] (snngp_vary_inducing_random:46) LML: 8542.244089141814
[2022-08-12 17:52:52,843 INFO] (snngp_vary_inducing_random:48) ELBO: 8503.297304298676
[2022-08-12 17:53:23,647 INFO] (snngp_vary_inducing_random:50) EUBO: 10842.342616682692
[2022-08-12 17:53:46,835 INFO] (snngp_vary_inducing_random:54) Loss: 0.10093235823515978
[2022-08-12 17:53:46,836 INFO] (snngp_vary_inducing_random:56) Accuracy: 97.36%
